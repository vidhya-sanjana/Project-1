{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMiPgOgYjzssIeJRkr0GKzR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aM61uEOfKvXc","executionInfo":{"status":"ok","timestamp":1696573197025,"user_tz":-330,"elapsed":29476,"user":{"displayName":"Vidhya Sanjana K","userId":"10741726791244027257"}},"outputId":"b7186001-eb3a-4d5f-fcda-6f8e648e50ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["#DEEP LEARNING:"],"metadata":{"id":"_ERK7zvsMEoG"}},{"cell_type":"markdown","source":["CLASSIFICATION:"],"metadata":{"id":"aNOlTTt9MOEs"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sklearn\n","\n","# Import necessary modules\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from math import sqrt\n","\n","# Keras specific\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.utils import to_categorical\n","df = pd.read_csv(\"/content/drive/MyDrive/ASW/heart.csv\")\n","x=df.drop('target',axis=1)\n","y=df['target']\n","x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=42)\n","model = Sequential()\n","model.add(Dense(500, activation='relu', input_dim=13))\n","model.add(Dense(100, activation='relu'))\n","model.add(Dense(50, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","model.fit(x_train,y_train, epochs=100)\n","print(model.predict(x_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oPB9rk3P7q5X","executionInfo":{"status":"ok","timestamp":1696578115128,"user_tz":-330,"elapsed":11385,"user":{"displayName":"Vidhya Sanjana K","userId":"10741726791244027257"}},"outputId":"e779cbdb-2d9c-41a6-e833-aa50b709302e"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","24/24 [==============================] - 2s 5ms/step - loss: 2.0899 - accuracy: 0.5729\n","Epoch 2/100\n","24/24 [==============================] - 0s 6ms/step - loss: 0.6873 - accuracy: 0.6901\n","Epoch 3/100\n","24/24 [==============================] - 0s 6ms/step - loss: 0.5814 - accuracy: 0.7070\n","Epoch 4/100\n","24/24 [==============================] - 0s 5ms/step - loss: 0.5470 - accuracy: 0.7070\n","Epoch 5/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.6215 - accuracy: 0.7070\n","Epoch 6/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.7126 - accuracy: 0.6784\n","Epoch 7/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.6629 - accuracy: 0.6953\n","Epoch 8/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7708\n","Epoch 9/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7656\n","Epoch 10/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7578\n","Epoch 11/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.7409\n","Epoch 12/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7839\n","Epoch 13/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8047\n","Epoch 14/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.7331\n","Epoch 15/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.8047\n","Epoch 16/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3896 - accuracy: 0.8333\n","Epoch 17/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.7799\n","Epoch 18/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3605 - accuracy: 0.8359\n","Epoch 19/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8477\n","Epoch 20/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.7747\n","Epoch 21/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.5772 - accuracy: 0.7487\n","Epoch 22/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7812\n","Epoch 23/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3742 - accuracy: 0.8255\n","Epoch 24/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.8112\n","Epoch 25/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7682\n","Epoch 26/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.8529\n","Epoch 27/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3581 - accuracy: 0.8451\n","Epoch 28/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3362 - accuracy: 0.8424\n","Epoch 29/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7786\n","Epoch 30/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3661 - accuracy: 0.8294\n","Epoch 31/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3538 - accuracy: 0.8451\n","Epoch 32/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3694 - accuracy: 0.8307\n","Epoch 33/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4127 - accuracy: 0.8164\n","Epoch 34/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3681 - accuracy: 0.8307\n","Epoch 35/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3460 - accuracy: 0.8320\n","Epoch 36/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3674 - accuracy: 0.8464\n","Epoch 37/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3890 - accuracy: 0.8151\n","Epoch 38/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7995\n","Epoch 39/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7669\n","Epoch 40/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.8555\n","Epoch 41/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3345 - accuracy: 0.8529\n","Epoch 42/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8555\n","Epoch 43/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3425 - accuracy: 0.8490\n","Epoch 44/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3337 - accuracy: 0.8555\n","Epoch 45/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3377 - accuracy: 0.8411\n","Epoch 46/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3429 - accuracy: 0.8451\n","Epoch 47/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3327 - accuracy: 0.8568\n","Epoch 48/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3266 - accuracy: 0.8568\n","Epoch 49/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3287 - accuracy: 0.8568\n","Epoch 50/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3271 - accuracy: 0.8568\n","Epoch 51/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3237 - accuracy: 0.8620\n","Epoch 52/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8568\n","Epoch 53/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3379 - accuracy: 0.8620\n","Epoch 54/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3393 - accuracy: 0.8594\n","Epoch 55/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3279 - accuracy: 0.8607\n","Epoch 56/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8464\n","Epoch 57/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3229 - accuracy: 0.8594\n","Epoch 58/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3207 - accuracy: 0.8633\n","Epoch 59/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3178 - accuracy: 0.8633\n","Epoch 60/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3211 - accuracy: 0.8685\n","Epoch 61/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3538 - accuracy: 0.8385\n","Epoch 62/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3618 - accuracy: 0.8268\n","Epoch 63/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3148 - accuracy: 0.8581\n","Epoch 64/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3276 - accuracy: 0.8607\n","Epoch 65/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3595 - accuracy: 0.8398\n","Epoch 66/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3187 - accuracy: 0.8568\n","Epoch 67/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3190 - accuracy: 0.8555\n","Epoch 68/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3319 - accuracy: 0.8503\n","Epoch 69/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3262 - accuracy: 0.8672\n","Epoch 70/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3417 - accuracy: 0.8529\n","Epoch 71/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3347 - accuracy: 0.8607\n","Epoch 72/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3273 - accuracy: 0.8568\n","Epoch 73/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3266 - accuracy: 0.8490\n","Epoch 74/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3399 - accuracy: 0.8503\n","Epoch 75/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3311 - accuracy: 0.8568\n","Epoch 76/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3806 - accuracy: 0.8294\n","Epoch 77/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3486 - accuracy: 0.8555\n","Epoch 78/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3459 - accuracy: 0.8451\n","Epoch 79/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3551 - accuracy: 0.8281\n","Epoch 80/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3122 - accuracy: 0.8659\n","Epoch 81/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3190 - accuracy: 0.8646\n","Epoch 82/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3666 - accuracy: 0.8555\n","Epoch 83/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3144 - accuracy: 0.8542\n","Epoch 84/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3604 - accuracy: 0.8438\n","Epoch 85/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3223 - accuracy: 0.8659\n","Epoch 86/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3176 - accuracy: 0.8568\n","Epoch 87/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3450 - accuracy: 0.8385\n","Epoch 88/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3205 - accuracy: 0.8451\n","Epoch 89/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3013 - accuracy: 0.8698\n","Epoch 90/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2934 - accuracy: 0.8802\n","Epoch 91/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3690 - accuracy: 0.8346\n","Epoch 92/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3287 - accuracy: 0.8633\n","Epoch 93/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2894 - accuracy: 0.8828\n","Epoch 94/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3163 - accuracy: 0.8685\n","Epoch 95/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.8451\n","Epoch 96/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3202 - accuracy: 0.8503\n","Epoch 97/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3030 - accuracy: 0.8737\n","Epoch 98/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3459 - accuracy: 0.8503\n","Epoch 99/100\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3315 - accuracy: 0.8451\n","Epoch 100/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3160 - accuracy: 0.8516\n","9/9 [==============================] - 0s 3ms/step\n","[[9.5870835e-01]\n"," [9.8368752e-01]\n"," [1.2741505e-02]\n"," [9.0644610e-01]\n"," [2.8049739e-02]\n"," [6.7423391e-01]\n"," [1.2414656e-02]\n"," [7.8496151e-03]\n"," [7.5318009e-01]\n"," [4.6147583e-03]\n"," [9.8664868e-01]\n"," [2.0465222e-03]\n"," [7.5925094e-01]\n"," [9.9998814e-01]\n"," [2.5488121e-02]\n"," [9.2656535e-01]\n"," [4.4070743e-03]\n"," [9.9939525e-01]\n"," [8.4683180e-01]\n"," [5.9072371e-03]\n"," [3.8727024e-01]\n"," [3.4363262e-02]\n"," [1.5657529e-01]\n"," [1.1279612e-03]\n"," [3.8727024e-01]\n"," [9.5045942e-01]\n"," [7.6186275e-01]\n"," [3.2676783e-01]\n"," [1.7516079e-03]\n"," [7.6216769e-01]\n"," [3.8018185e-01]\n"," [2.0422973e-01]\n"," [4.6702257e-01]\n"," [9.8368752e-01]\n"," [7.6789194e-01]\n"," [8.3768415e-01]\n"," [3.8727024e-01]\n"," [2.1506299e-01]\n"," [8.0704230e-01]\n"," [9.3353778e-01]\n"," [7.8496151e-03]\n"," [1.7359756e-02]\n"," [5.5118662e-01]\n"," [1.5657529e-01]\n"," [5.0690570e-03]\n"," [1.6855001e-03]\n"," [2.9607089e-02]\n"," [2.5094888e-01]\n"," [4.6099758e-01]\n"," [3.7869045e-01]\n"," [1.7338543e-01]\n"," [2.1096726e-03]\n"," [6.2186086e-01]\n"," [2.8877722e-03]\n"," [7.6186275e-01]\n"," [8.0704230e-01]\n"," [9.2578180e-02]\n"," [3.5391741e-03]\n"," [8.0759245e-01]\n"," [9.3037063e-01]\n"," [4.1319591e-01]\n"," [4.8721530e-02]\n"," [1.7516071e-03]\n"," [3.7869072e-01]\n"," [4.7133514e-03]\n"," [2.3881767e-02]\n"," [9.9765950e-01]\n"," [2.3534852e-01]\n"," [1.6855001e-03]\n"," [9.8211926e-01]\n"," [5.5372047e-01]\n"," [1.7516079e-03]\n"," [2.3553658e-01]\n"," [8.8690180e-01]\n"," [6.2276024e-01]\n"," [3.8766080e-01]\n"," [1.2414656e-02]\n"," [5.6029117e-01]\n"," [3.2594556e-01]\n"," [7.3914504e-01]\n"," [1.2599494e-01]\n"," [6.3736290e-02]\n"," [5.4286607e-03]\n"," [8.4250513e-03]\n"," [8.7937695e-01]\n"," [2.0068618e-03]\n"," [9.8664868e-01]\n"," [5.0599083e-02]\n"," [1.2599494e-01]\n"," [7.6216769e-01]\n"," [5.0053799e-01]\n"," [5.9072371e-03]\n"," [9.3540454e-01]\n"," [8.5306919e-01]\n"," [8.5787940e-01]\n"," [6.1056644e-01]\n"," [2.3534852e-01]\n"," [1.0849503e-02]\n"," [2.8480400e-04]\n"," [2.4053235e-02]\n"," [9.9961603e-01]\n"," [3.1091021e-02]\n"," [5.4799873e-01]\n"," [5.4658121e-01]\n"," [3.3394445e-02]\n"," [9.5334649e-01]\n"," [3.5391741e-03]\n"," [6.4399004e-01]\n"," [1.1192954e-01]\n"," [9.2617106e-01]\n"," [8.0759245e-01]\n"," [9.2617106e-01]\n"," [9.7484660e-01]\n"," [2.4321690e-02]\n"," [7.4503601e-01]\n"," [9.4232363e-01]\n"," [5.8539838e-01]\n"," [8.0275917e-01]\n"," [8.8722104e-01]\n"," [1.3402662e-03]\n"," [3.7518594e-01]\n"," [5.0779796e-01]\n"," [2.2762159e-03]\n"," [9.4760045e-02]\n"," [4.3583829e-02]\n"," [1.1279612e-03]\n"," [7.8754139e-01]\n"," [5.4019696e-01]\n"," [5.5372047e-01]\n"," [7.6636219e-01]\n"," [2.0422979e-01]\n"," [2.8480400e-04]\n"," [9.8077548e-01]\n"," [9.9961603e-01]\n"," [4.9198139e-03]\n"," [9.7498745e-01]\n"," [6.2080444e-04]\n"," [5.0779796e-01]\n"," [9.7498745e-01]\n"," [5.8539838e-01]\n"," [6.6729558e-01]\n"," [8.7017548e-01]\n"," [9.4453281e-01]\n"," [3.9644696e-02]\n"," [3.6624563e-01]\n"," [9.0222061e-01]\n"," [1.7338543e-01]\n"," [8.8946468e-01]\n"," [4.4765666e-01]\n"," [1.1706286e-02]\n"," [4.6702257e-01]\n"," [1.6855001e-03]\n"," [7.3219138e-01]\n"," [6.6729558e-01]\n"," [9.1061339e-02]\n"," [3.2725990e-02]\n"," [7.5894701e-01]\n"," [7.6636219e-01]\n"," [2.8297523e-02]\n"," [1.7359771e-02]\n"," [5.5118662e-01]\n"," [9.8401135e-01]\n"," [3.1091021e-02]\n"," [3.1091021e-02]\n"," [5.6373484e-02]\n"," [7.4707247e-02]\n"," [4.5244414e-02]\n"," [8.3387000e-03]\n"," [7.3403083e-02]\n"," [8.8946468e-01]\n"," [2.3553658e-01]\n"," [4.5307958e-01]\n"," [9.9086261e-01]\n"," [1.2847712e-05]\n"," [8.5962254e-01]\n"," [9.8368752e-01]\n"," [9.9255401e-01]\n"," [2.6854532e-04]\n"," [5.4799873e-01]\n"," [9.3618679e-01]\n"," [9.5810938e-01]\n"," [3.6045124e-03]\n"," [6.6002434e-01]\n"," [6.2186086e-01]\n"," [6.1398858e-01]\n"," [8.8722104e-01]\n"," [7.6789194e-01]\n"," [8.0759245e-01]\n"," [6.1146319e-01]\n"," [9.4781065e-01]\n"," [9.6263283e-01]\n"," [3.2594535e-01]\n"," [6.5883166e-01]\n"," [6.2186086e-01]\n"," [3.5391741e-03]\n"," [7.0496053e-02]\n"," [8.6618018e-01]\n"," [2.2463216e-03]\n"," [9.2125183e-01]\n"," [9.6538508e-01]\n"," [3.1176051e-01]\n"," [7.3376733e-01]\n"," [9.6538508e-01]\n"," [1.3570962e-02]\n"," [1.9523427e-01]\n"," [8.5912868e-02]\n"," [3.5100040e-01]\n"," [9.8368931e-01]\n"," [4.9839821e-01]\n"," [5.0779796e-01]\n"," [7.3376733e-01]\n"," [4.8395313e-02]\n"," [9.9831432e-01]\n"," [5.0053799e-01]\n"," [3.2725990e-02]\n"," [6.9473192e-02]\n"," [3.8825679e-01]\n"," [4.5244414e-02]\n"," [5.2911937e-01]\n"," [4.9198139e-03]\n"," [5.4850298e-01]\n"," [5.4286607e-03]\n"," [2.4053240e-02]\n"," [9.4511378e-01]\n"," [8.6449885e-01]\n"," [7.3166347e-01]\n"," [8.0275917e-01]\n"," [4.0200287e-01]\n"," [2.0465222e-03]\n"," [3.7518594e-01]\n"," [6.5883166e-01]\n"," [2.7286485e-01]\n"," [5.5811810e-01]\n"," [7.5894701e-01]\n"," [1.1706286e-02]\n"," [1.2414656e-02]\n"," [1.3862707e-01]\n"," [4.9424779e-02]\n"," [9.3970156e-01]\n"," [2.9129654e-01]\n"," [2.5190288e-01]\n"," [1.9948582e-01]\n"," [9.9957377e-01]\n"," [4.9721681e-02]\n"," [6.2442380e-03]\n"," [6.4399004e-01]\n"," [2.3255628e-02]\n"," [9.9961603e-01]\n"," [7.8921026e-01]\n"," [4.8468772e-02]\n"," [8.8690180e-01]\n"," [4.6147583e-03]\n"," [3.0809510e-01]\n"," [2.6854532e-04]\n"," [9.4760031e-02]\n"," [9.2174786e-01]\n"," [1.2537285e-02]]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sklearn\n","\n","# Import necessary modules\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from math import sqrt\n","\n","# Keras specific\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.utils import to_categorical\n","df = pd.read_csv(\"/content/drive/MyDrive/ASW/heart.csv\")\n","x=df.drop('target',axis=1)\n","y=df['target']\n","x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=42)\n","model = Sequential()\n","model.add(Dense(1000, activation='relu', input_dim=13))\n","model.add(Dense(500, activation='relu'))\n","model.add(Dense(100, activation='relu'))\n","model.add(Dense(50, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","model.fit(x_train,y_train, epochs=200)\n","print(model.predict(x_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bUc9KDGJMELx","executionInfo":{"status":"ok","timestamp":1696573294194,"user_tz":-330,"elapsed":89468,"user":{"displayName":"Vidhya Sanjana K","userId":"10741726791244027257"}},"outputId":"b62a6d88-4129-45a1-d18c-f4baa8a8f5a6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","24/24 [==============================] - 2s 11ms/step - loss: 1.4863 - accuracy: 0.5781\n","Epoch 2/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.6713 - accuracy: 0.6406\n","Epoch 3/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.6609 - accuracy: 0.6445\n","Epoch 4/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.6372 - accuracy: 0.6940\n","Epoch 5/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.6370 - accuracy: 0.6497\n","Epoch 6/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.5862 - accuracy: 0.6927\n","Epoch 7/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.6197 - accuracy: 0.6719\n","Epoch 8/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.5294 - accuracy: 0.7240\n","Epoch 9/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.4819 - accuracy: 0.7617\n","Epoch 10/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.4997 - accuracy: 0.7734\n","Epoch 11/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.4568 - accuracy: 0.7865\n","Epoch 12/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.4447 - accuracy: 0.8060\n","Epoch 13/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.4362 - accuracy: 0.7852\n","Epoch 14/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.4170 - accuracy: 0.8112\n","Epoch 15/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3910 - accuracy: 0.8307\n","Epoch 16/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.4523 - accuracy: 0.8034\n","Epoch 17/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.4472 - accuracy: 0.7969\n","Epoch 18/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3749 - accuracy: 0.8372\n","Epoch 19/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.3601 - accuracy: 0.8411\n","Epoch 20/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3936 - accuracy: 0.8216\n","Epoch 21/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.4359 - accuracy: 0.8086\n","Epoch 22/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.4379 - accuracy: 0.7943\n","Epoch 23/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.4044 - accuracy: 0.8164\n","Epoch 24/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.3821 - accuracy: 0.8385\n","Epoch 25/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3987 - accuracy: 0.8073\n","Epoch 26/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.4234 - accuracy: 0.8021\n","Epoch 27/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3981 - accuracy: 0.7982\n","Epoch 28/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3928 - accuracy: 0.8255\n","Epoch 29/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3799 - accuracy: 0.8190\n","Epoch 30/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3498 - accuracy: 0.8490\n","Epoch 31/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.3685 - accuracy: 0.8451\n","Epoch 32/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.4278 - accuracy: 0.7995\n","Epoch 33/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.3409 - accuracy: 0.8607\n","Epoch 34/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.3608 - accuracy: 0.8372\n","Epoch 35/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.3593 - accuracy: 0.8490\n","Epoch 36/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.3612 - accuracy: 0.8503\n","Epoch 37/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.3941 - accuracy: 0.8320\n","Epoch 38/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.3888 - accuracy: 0.8190\n","Epoch 39/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.3679 - accuracy: 0.8294\n","Epoch 40/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.3713 - accuracy: 0.8398\n","Epoch 41/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.3789 - accuracy: 0.8229\n","Epoch 42/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.3514 - accuracy: 0.8464\n","Epoch 43/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.3528 - accuracy: 0.8359\n","Epoch 44/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.3301 - accuracy: 0.8516\n","Epoch 45/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3407 - accuracy: 0.8659\n","Epoch 46/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3204 - accuracy: 0.8620\n","Epoch 47/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3409 - accuracy: 0.8516\n","Epoch 48/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3437 - accuracy: 0.8490\n","Epoch 49/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3325 - accuracy: 0.8555\n","Epoch 50/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3216 - accuracy: 0.8776\n","Epoch 51/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3487 - accuracy: 0.8307\n","Epoch 52/200\n","24/24 [==============================] - 0s 13ms/step - loss: 0.3476 - accuracy: 0.8490\n","Epoch 53/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3159 - accuracy: 0.8594\n","Epoch 54/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3480 - accuracy: 0.8516\n","Epoch 55/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3480 - accuracy: 0.8529\n","Epoch 56/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.3455 - accuracy: 0.8503\n","Epoch 57/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.3552 - accuracy: 0.8411\n","Epoch 58/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3197 - accuracy: 0.8698\n","Epoch 59/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3198 - accuracy: 0.8620\n","Epoch 60/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3242 - accuracy: 0.8724\n","Epoch 61/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3295 - accuracy: 0.8659\n","Epoch 62/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3162 - accuracy: 0.8620\n","Epoch 63/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3140 - accuracy: 0.8659\n","Epoch 64/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3141 - accuracy: 0.8672\n","Epoch 65/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.3209 - accuracy: 0.8594\n","Epoch 66/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3098 - accuracy: 0.8594\n","Epoch 67/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2997 - accuracy: 0.8698\n","Epoch 68/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3189 - accuracy: 0.8750\n","Epoch 69/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3005 - accuracy: 0.8646\n","Epoch 70/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3391 - accuracy: 0.8490\n","Epoch 71/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3129 - accuracy: 0.8672\n","Epoch 72/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3178 - accuracy: 0.8646\n","Epoch 73/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3055 - accuracy: 0.8763\n","Epoch 74/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2926 - accuracy: 0.8828\n","Epoch 75/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3110 - accuracy: 0.8646\n","Epoch 76/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.3166 - accuracy: 0.8711\n","Epoch 77/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3176 - accuracy: 0.8633\n","Epoch 78/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3422 - accuracy: 0.8594\n","Epoch 79/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3112 - accuracy: 0.8698\n","Epoch 80/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.2992 - accuracy: 0.8711\n","Epoch 81/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.3230 - accuracy: 0.8672\n","Epoch 82/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.2960 - accuracy: 0.8698\n","Epoch 83/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.2803 - accuracy: 0.8815\n","Epoch 84/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.2873 - accuracy: 0.8750\n","Epoch 85/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.3114 - accuracy: 0.8594\n","Epoch 86/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.3077 - accuracy: 0.8685\n","Epoch 87/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.3346 - accuracy: 0.8542\n","Epoch 88/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.3188 - accuracy: 0.8594\n","Epoch 89/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.3505 - accuracy: 0.8633\n","Epoch 90/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.3673 - accuracy: 0.8398\n","Epoch 91/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.3449 - accuracy: 0.8477\n","Epoch 92/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.3008 - accuracy: 0.8737\n","Epoch 93/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.2879 - accuracy: 0.8802\n","Epoch 94/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.2741 - accuracy: 0.8789\n","Epoch 95/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2747 - accuracy: 0.8867\n","Epoch 96/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2988 - accuracy: 0.8763\n","Epoch 97/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.3620 - accuracy: 0.8438\n","Epoch 98/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3350 - accuracy: 0.8451\n","Epoch 99/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3851 - accuracy: 0.8281\n","Epoch 100/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3454 - accuracy: 0.8633\n","Epoch 101/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.2868 - accuracy: 0.8828\n","Epoch 102/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.2856 - accuracy: 0.8763\n","Epoch 103/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2788 - accuracy: 0.8932\n","Epoch 104/200\n","24/24 [==============================] - 0s 18ms/step - loss: 0.2626 - accuracy: 0.8880\n","Epoch 105/200\n","24/24 [==============================] - 1s 21ms/step - loss: 0.2689 - accuracy: 0.8893\n","Epoch 106/200\n","24/24 [==============================] - 0s 19ms/step - loss: 0.2906 - accuracy: 0.8750\n","Epoch 107/200\n","24/24 [==============================] - 0s 18ms/step - loss: 0.2872 - accuracy: 0.8841\n","Epoch 108/200\n","24/24 [==============================] - 0s 20ms/step - loss: 0.2958 - accuracy: 0.8620\n","Epoch 109/200\n","24/24 [==============================] - 0s 20ms/step - loss: 0.2932 - accuracy: 0.8698\n","Epoch 110/200\n","24/24 [==============================] - 0s 18ms/step - loss: 0.2811 - accuracy: 0.8789\n","Epoch 111/200\n","24/24 [==============================] - 1s 22ms/step - loss: 0.2765 - accuracy: 0.8659\n","Epoch 112/200\n","24/24 [==============================] - 0s 18ms/step - loss: 0.2677 - accuracy: 0.8893\n","Epoch 113/200\n","24/24 [==============================] - 0s 19ms/step - loss: 0.2776 - accuracy: 0.8750\n","Epoch 114/200\n","24/24 [==============================] - 0s 20ms/step - loss: 0.2594 - accuracy: 0.8906\n","Epoch 115/200\n","24/24 [==============================] - 0s 19ms/step - loss: 0.3572 - accuracy: 0.8333\n","Epoch 116/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.3290 - accuracy: 0.8503\n","Epoch 117/200\n","24/24 [==============================] - 0s 19ms/step - loss: 0.2812 - accuracy: 0.8828\n","Epoch 118/200\n","24/24 [==============================] - 0s 18ms/step - loss: 0.3284 - accuracy: 0.8516\n","Epoch 119/200\n","24/24 [==============================] - 1s 29ms/step - loss: 0.2613 - accuracy: 0.8906\n","Epoch 120/200\n","24/24 [==============================] - 1s 29ms/step - loss: 0.2611 - accuracy: 0.8854\n","Epoch 121/200\n","24/24 [==============================] - 1s 22ms/step - loss: 0.2956 - accuracy: 0.8737\n","Epoch 122/200\n","24/24 [==============================] - 1s 22ms/step - loss: 0.2709 - accuracy: 0.8711\n","Epoch 123/200\n","24/24 [==============================] - 1s 30ms/step - loss: 0.2412 - accuracy: 0.8971\n","Epoch 124/200\n","24/24 [==============================] - 1s 24ms/step - loss: 0.3014 - accuracy: 0.8503\n","Epoch 125/200\n","24/24 [==============================] - 1s 30ms/step - loss: 0.2440 - accuracy: 0.8932\n","Epoch 126/200\n","24/24 [==============================] - 0s 20ms/step - loss: 0.2558 - accuracy: 0.8867\n","Epoch 127/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.2590 - accuracy: 0.8698\n","Epoch 128/200\n","24/24 [==============================] - 0s 14ms/step - loss: 0.2514 - accuracy: 0.8958\n","Epoch 129/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2311 - accuracy: 0.9023\n","Epoch 130/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2475 - accuracy: 0.8906\n","Epoch 131/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2645 - accuracy: 0.8841\n","Epoch 132/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2822 - accuracy: 0.8737\n","Epoch 133/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2539 - accuracy: 0.8854\n","Epoch 134/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.2623 - accuracy: 0.8867\n","Epoch 135/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.2205 - accuracy: 0.9062\n","Epoch 136/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2235 - accuracy: 0.8958\n","Epoch 137/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2281 - accuracy: 0.8997\n","Epoch 138/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2425 - accuracy: 0.8984\n","Epoch 139/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3160 - accuracy: 0.8594\n","Epoch 140/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2891 - accuracy: 0.8763\n","Epoch 141/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.2706 - accuracy: 0.8854\n","Epoch 142/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.2438 - accuracy: 0.8919\n","Epoch 143/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2244 - accuracy: 0.9049\n","Epoch 144/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2082 - accuracy: 0.9141\n","Epoch 145/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.2082 - accuracy: 0.8984\n","Epoch 146/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2579 - accuracy: 0.8893\n","Epoch 147/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.3617 - accuracy: 0.8333\n","Epoch 148/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.3236 - accuracy: 0.8594\n","Epoch 149/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2435 - accuracy: 0.8945\n","Epoch 150/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.2199 - accuracy: 0.8945\n","Epoch 151/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2130 - accuracy: 0.9076\n","Epoch 152/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.1991 - accuracy: 0.9167\n","Epoch 153/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2042 - accuracy: 0.9115\n","Epoch 154/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1884 - accuracy: 0.9154\n","Epoch 155/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.1798 - accuracy: 0.9206\n","Epoch 156/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2265 - accuracy: 0.9010\n","Epoch 157/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2332 - accuracy: 0.8984\n","Epoch 158/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2327 - accuracy: 0.9036\n","Epoch 159/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.2838 - accuracy: 0.8724\n","Epoch 160/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2506 - accuracy: 0.8906\n","Epoch 161/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2312 - accuracy: 0.8906\n","Epoch 162/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2016 - accuracy: 0.9167\n","Epoch 163/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.1870 - accuracy: 0.9180\n","Epoch 164/200\n","24/24 [==============================] - 0s 14ms/step - loss: 0.2414 - accuracy: 0.8945\n","Epoch 165/200\n","24/24 [==============================] - 0s 18ms/step - loss: 0.2249 - accuracy: 0.9128\n","Epoch 166/200\n","24/24 [==============================] - 1s 34ms/step - loss: 0.1943 - accuracy: 0.9115\n","Epoch 167/200\n","24/24 [==============================] - 1s 37ms/step - loss: 0.2008 - accuracy: 0.9128\n","Epoch 168/200\n","24/24 [==============================] - 1s 31ms/step - loss: 0.1945 - accuracy: 0.9115\n","Epoch 169/200\n","24/24 [==============================] - 1s 40ms/step - loss: 0.1656 - accuracy: 0.9271\n","Epoch 170/200\n","24/24 [==============================] - 1s 23ms/step - loss: 0.1487 - accuracy: 0.9388\n","Epoch 171/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.1756 - accuracy: 0.9232\n","Epoch 172/200\n","24/24 [==============================] - 0s 18ms/step - loss: 0.1683 - accuracy: 0.9284\n","Epoch 173/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.1790 - accuracy: 0.9219\n","Epoch 174/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2278 - accuracy: 0.9023\n","Epoch 175/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2543 - accuracy: 0.9010\n","Epoch 176/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1791 - accuracy: 0.9258\n","Epoch 177/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.1963 - accuracy: 0.9089\n","Epoch 178/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.1881 - accuracy: 0.9167\n","Epoch 179/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.1478 - accuracy: 0.9388\n","Epoch 180/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1430 - accuracy: 0.9414\n","Epoch 181/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1598 - accuracy: 0.9336\n","Epoch 182/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1668 - accuracy: 0.9349\n","Epoch 183/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1469 - accuracy: 0.9414\n","Epoch 184/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1317 - accuracy: 0.9531\n","Epoch 185/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1263 - accuracy: 0.9505\n","Epoch 186/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.1333 - accuracy: 0.9492\n","Epoch 187/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.1365 - accuracy: 0.9492\n","Epoch 188/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.1787 - accuracy: 0.9141\n","Epoch 189/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1650 - accuracy: 0.9297\n","Epoch 190/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2364 - accuracy: 0.9102\n","Epoch 191/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2174 - accuracy: 0.8971\n","Epoch 192/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.1782 - accuracy: 0.9167\n","Epoch 193/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.1434 - accuracy: 0.9401\n","Epoch 194/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1139 - accuracy: 0.9570\n","Epoch 195/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1009 - accuracy: 0.9622\n","Epoch 196/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.1055 - accuracy: 0.9596\n","Epoch 197/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1395 - accuracy: 0.9427\n","Epoch 198/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1504 - accuracy: 0.9388\n","Epoch 199/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2969 - accuracy: 0.8750\n","Epoch 200/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2729 - accuracy: 0.8919\n","9/9 [==============================] - 0s 6ms/step\n","[[9.6138644e-01]\n"," [9.9991250e-01]\n"," [5.9707835e-04]\n"," [9.7666639e-01]\n"," [2.1909543e-04]\n"," [9.9965477e-01]\n"," [7.5308289e-03]\n"," [1.0103702e-03]\n"," [8.3312207e-01]\n"," [2.6095429e-05]\n"," [9.2957532e-01]\n"," [1.2024604e-05]\n"," [9.9312162e-01]\n"," [1.0000000e+00]\n"," [1.2808603e-03]\n"," [8.7995350e-01]\n"," [1.2431789e-05]\n"," [1.0000000e+00]\n"," [9.9999982e-01]\n"," [4.9027522e-06]\n"," [6.8216217e-01]\n"," [3.3630809e-04]\n"," [3.5296202e-01]\n"," [2.3350172e-10]\n"," [6.8216217e-01]\n"," [9.9993318e-01]\n"," [9.8076320e-01]\n"," [8.9419681e-01]\n"," [6.1705831e-12]\n"," [8.8096792e-01]\n"," [2.3544656e-01]\n"," [8.7890726e-01]\n"," [1.3808113e-01]\n"," [9.9991250e-01]\n"," [9.9363363e-01]\n"," [8.6857450e-01]\n"," [6.8216217e-01]\n"," [5.4603946e-01]\n"," [8.9139283e-01]\n"," [9.9238902e-01]\n"," [1.0103702e-03]\n"," [1.0129155e-02]\n"," [6.0350096e-01]\n"," [3.5296202e-01]\n"," [4.7022022e-05]\n"," [1.5161194e-07]\n"," [8.5695535e-01]\n"," [2.3381296e-03]\n"," [9.8686385e-01]\n"," [4.5512998e-01]\n"," [1.9792035e-01]\n"," [1.3308678e-08]\n"," [4.2470604e-01]\n"," [2.2633937e-03]\n"," [9.8076320e-01]\n"," [8.9139283e-01]\n"," [2.8038255e-04]\n"," [2.4246739e-04]\n"," [6.6830003e-01]\n"," [9.9948889e-01]\n"," [2.0202470e-01]\n"," [9.6293122e-01]\n"," [6.1705476e-12]\n"," [4.5512992e-01]\n"," [1.5070166e-05]\n"," [1.4160796e-01]\n"," [9.9997991e-01]\n"," [1.4402540e-01]\n"," [1.5161194e-07]\n"," [9.9933970e-01]\n"," [7.1695107e-01]\n"," [6.1705831e-12]\n"," [4.0212074e-01]\n"," [9.5016974e-01]\n"," [9.1201460e-01]\n"," [5.2973461e-01]\n"," [7.5308289e-03]\n"," [5.5959653e-02]\n"," [1.8929715e-01]\n"," [9.7473508e-01]\n"," [4.2144966e-01]\n"," [6.8866974e-01]\n"," [1.8791972e-05]\n"," [1.0796023e-09]\n"," [9.7353435e-01]\n"," [7.2029232e-12]\n"," [9.2957532e-01]\n"," [9.3891611e-03]\n"," [4.2144966e-01]\n"," [8.8096792e-01]\n"," [1.1360269e-01]\n"," [4.9027522e-06]\n"," [9.9999964e-01]\n"," [9.7416127e-01]\n"," [8.4348518e-01]\n"," [7.2735542e-01]\n"," [1.4402540e-01]\n"," [6.1187975e-06]\n"," [2.6899022e-07]\n"," [2.7717999e-03]\n"," [1.0000000e+00]\n"," [2.8807251e-02]\n"," [6.2547916e-01]\n"," [9.0209758e-01]\n"," [3.1133092e-03]\n"," [9.9987471e-01]\n"," [2.4246739e-04]\n"," [4.1826028e-01]\n"," [8.7678414e-03]\n"," [9.9812567e-01]\n"," [6.6830003e-01]\n"," [9.9812567e-01]\n"," [9.9997509e-01]\n"," [2.3470246e-03]\n"," [9.4814891e-01]\n"," [9.9937874e-01]\n"," [8.4155446e-01]\n"," [9.7614461e-01]\n"," [9.2668098e-01]\n"," [3.7668024e-09]\n"," [9.7569168e-01]\n"," [7.2956145e-01]\n"," [5.7178092e-11]\n"," [1.4295353e-02]\n"," [3.0291396e-01]\n"," [2.3350172e-10]\n"," [9.8069215e-01]\n"," [3.2081181e-01]\n"," [7.1695107e-01]\n"," [9.4061965e-01]\n"," [8.7890726e-01]\n"," [2.6899022e-07]\n"," [9.9834698e-01]\n"," [1.0000000e+00]\n"," [2.9855829e-09]\n"," [1.0000000e+00]\n"," [2.1620024e-06]\n"," [7.2956145e-01]\n"," [1.0000000e+00]\n"," [8.4155446e-01]\n"," [5.7086122e-01]\n"," [8.7146169e-01]\n"," [9.9620384e-01]\n"," [8.8445604e-01]\n"," [7.2029042e-01]\n"," [7.7641708e-01]\n"," [1.9792035e-01]\n"," [9.8391992e-01]\n"," [3.9877993e-01]\n"," [7.3613137e-08]\n"," [1.3808113e-01]\n"," [1.5161194e-07]\n"," [9.1320688e-01]\n"," [5.7086122e-01]\n"," [1.2634429e-01]\n"," [5.3186342e-04]\n"," [7.0988303e-01]\n"," [9.4061965e-01]\n"," [2.8075115e-04]\n"," [1.0129164e-02]\n"," [6.0350096e-01]\n"," [9.9941969e-01]\n"," [2.8807251e-02]\n"," [2.8807251e-02]\n"," [9.7280562e-01]\n"," [8.9561760e-01]\n"," [1.3760738e-03]\n"," [3.3350643e-05]\n"," [8.9642310e-01]\n"," [9.8391992e-01]\n"," [4.0212074e-01]\n"," [8.4402621e-01]\n"," [9.9995732e-01]\n"," [1.3247885e-17]\n"," [8.6903465e-01]\n"," [9.9991250e-01]\n"," [1.0000000e+00]\n"," [1.2097844e-13]\n"," [6.2547916e-01]\n"," [9.9414301e-01]\n"," [9.9998230e-01]\n"," [2.2310739e-06]\n"," [9.9389583e-01]\n"," [4.2470604e-01]\n"," [3.0629653e-01]\n"," [9.2668098e-01]\n"," [9.9363363e-01]\n"," [6.6830003e-01]\n"," [7.0817953e-01]\n"," [9.9914461e-01]\n"," [9.9452615e-01]\n"," [1.8929707e-01]\n"," [3.1497568e-02]\n"," [4.2470604e-01]\n"," [2.4246739e-04]\n"," [3.0184370e-01]\n"," [9.1879821e-01]\n"," [1.4398670e-09]\n"," [9.9961114e-01]\n"," [9.9749142e-01]\n"," [5.4958671e-01]\n"," [9.0457773e-01]\n"," [9.9749142e-01]\n"," [2.4555920e-02]\n"," [1.0460988e-01]\n"," [6.8347707e-02]\n"," [8.5235453e-01]\n"," [9.6032238e-01]\n"," [4.4213378e-01]\n"," [7.2956145e-01]\n"," [9.0457773e-01]\n"," [2.4533500e-03]\n"," [1.0000000e+00]\n"," [1.1360269e-01]\n"," [5.3186342e-04]\n"," [1.0296641e-01]\n"," [2.4777748e-01]\n"," [1.3760738e-03]\n"," [4.4936687e-01]\n"," [2.9855829e-09]\n"," [6.6417795e-01]\n"," [1.8791972e-05]\n"," [2.7717974e-03]\n"," [9.9844271e-01]\n"," [9.8631680e-01]\n"," [8.5762626e-01]\n"," [9.7614461e-01]\n"," [7.7811158e-01]\n"," [1.2024604e-05]\n"," [9.7569168e-01]\n"," [3.1497568e-02]\n"," [2.4119196e-02]\n"," [2.5626546e-01]\n"," [7.0988303e-01]\n"," [7.3613137e-08]\n"," [7.5308289e-03]\n"," [3.2160837e-02]\n"," [2.3884622e-03]\n"," [9.4370848e-01]\n"," [7.2312713e-01]\n"," [1.9986947e-01]\n"," [1.8319589e-01]\n"," [1.0000000e+00]\n"," [1.1945900e-03]\n"," [4.5282350e-06]\n"," [4.1826028e-01]\n"," [7.3240087e-03]\n"," [1.0000000e+00]\n"," [8.7671095e-01]\n"," [3.4125525e-01]\n"," [9.5016974e-01]\n"," [2.6095429e-05]\n"," [5.3927058e-01]\n"," [1.2097844e-13]\n"," [1.4295360e-02]\n"," [9.9999720e-01]\n"," [2.8393779e-11]]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sklearn\n","\n","# Import necessary modules\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from math import sqrt\n","\n","# Keras specific\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.utils import to_categorical\n","df = pd.read_csv(\"/content/drive/MyDrive/ASW/heart.csv\")\n","x=df.drop('target',axis=1)\n","y=df['target']\n","x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=42)\n","model = Sequential()\n","model.add(Dense(1000, activation='relu', input_dim=13))\n","model.add(Dense(500, activation='relu'))\n","model.add(Dense(100, activation='relu'))\n","model.add(Dense(50, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","model.fit(x_train,y_train, epochs=200)\n","print(model.predict(x_test))"],"metadata":{"id":"vVIVI5eG7TBP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#MACHINE LEARNING:\n","\n"],"metadata":{"id":"RqvZGv-cNkMY"}},{"cell_type":"markdown","source":["\n","**DECISION TREE:**\n"],"metadata":{"id":"lmV_kXyUNrQh"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.model_selection import train_test_split\n","\n","# Load the dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/ASW/heart.csv\")\n","\n","# Split the data into features (x) and target labels (y)\n","x = df.drop('target', axis=1)\n","y = df['target']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n","\n","# Create and train the Decision Tree Classifier\n","classifier = DecisionTreeClassifier(criterion='entropy', random_state=0)\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = classifier.predict(X_test)\n","\n","# Calculate accuracy on the test set\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy}')\n","\n","# You can also print the classification report for more detailed evaluation\n","report = classification_report(y_test, y_pred)\n","print('Classification Report:\\n', report)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_b9JqNhjNaCv","executionInfo":{"status":"ok","timestamp":1696573748815,"user_tz":-330,"elapsed":420,"user":{"displayName":"Vidhya Sanjana K","userId":"10741726791244027257"}},"outputId":"dc494f73-8ac9-483b-8086-6b823b362a33"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 1.0\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        98\n","           1       1.00      1.00      1.00       107\n","\n","    accuracy                           1.00       205\n","   macro avg       1.00      1.00      1.00       205\n","weighted avg       1.00      1.00      1.00       205\n","\n"]}]},{"cell_type":"markdown","source":["**RANDOM FOREST**"],"metadata":{"id":"XDzYeWjEeWtL"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import train_test_split\n","\n","# Load your dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/ASW/heart.csv\")\n","\n","# Separate features (X) and target variable (y)\n","X = df.drop('target', axis=1)\n","y = df['target']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","# Create a RandomForestRegressor\n","RandomForestRegModel = RandomForestRegressor()\n","RandomForestRegModel.fit(X_train, y_train)\n","\n","# Make regression predictions on the test set\n","y_pred = RandomForestRegModel.predict(X_test)\n","print(y_pred)\n","# Define a threshold for considering a prediction as accurate (you can adjust this threshold)\n","accuracy_threshold = 0.5\n","\n","# Calculate the accuracy based on the threshold\n","accurate_predictions = np.abs(y_pred - y_test) <= accuracy_threshold\n","accuracy = np.mean(accurate_predictions) * 100.0\n","\n","print(f'Accuracy: {accuracy:.2f}%')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"labF2wwJjoqJ","executionInfo":{"status":"ok","timestamp":1696574013478,"user_tz":-330,"elapsed":1438,"user":{"displayName":"Vidhya Sanjana K","userId":"10741726791244027257"}},"outputId":"650c572b-a5ec-4011-dba8-0bf2becf3b9a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[1.   0.06 0.   1.   0.   0.02 0.01 0.   0.   0.   0.02 0.01 0.96 0.09\n"," 1.   0.81 1.   0.   1.   0.   1.   0.98 0.93 0.98 0.81 1.   1.   0.07\n"," 1.   0.81 0.99 0.   0.   0.98 0.01 0.   0.2  0.   0.85 1.   0.05 1.\n"," 0.99 1.   1.   1.   1.   0.06 0.   0.07 0.04 0.   0.94 0.02 0.03 0.\n"," 0.   0.83 0.03 0.06 0.   0.01 1.   0.07 0.1  0.   0.   1.   0.94 1.\n"," 0.93 1.   1.   0.   0.04 0.03 0.1  0.87 0.03 0.   0.   0.04 0.96 0.17\n"," 1.   0.   0.96 0.   1.   0.   0.   0.01 1.   0.96 0.97 0.   0.07 0.\n"," 1.   1.   0.82 0.9  0.99 0.01 0.03 1.   0.   0.96 0.03 0.99 0.92 0.14\n"," 0.96 0.01 0.91 0.02 0.94 0.   0.   0.9  0.03 0.85 1.   0.   0.01 1.\n"," 0.98 0.96 0.97 0.   0.   0.01 1.   0.99 0.93 0.09 0.   0.97 0.   0.99\n"," 0.9  0.02 0.95 0.01 0.2  1.   0.98 0.96 0.93 0.04 0.96 0.94 0.93 0.03\n"," 0.06 0.   0.97 0.97 0.01 0.03 0.03 0.99 0.99 0.02 0.9  0.97 1.   1.\n"," 0.81 0.98 1.   0.99 0.96 0.94 0.98 1.   0.11 0.99 1.   0.   0.   0.88\n"," 0.   0.06 1.   0.02 0.77 0.02 0.97 0.   0.04 0.96 0.07 1.   0.   0.88\n"," 0.77 1.   0.09 0.03 1.   1.   1.   0.   0.98]\n","Accuracy: 100.00%\n"]}]},{"cell_type":"markdown","source":["**SVM**"],"metadata":{"id":"CrmQ1vcPi3QU"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# Load the heart dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/ASW/heart.csv\")\n","\n","# Select features and target variable\n","X = df.drop('target', axis=1)\n","y = df['target']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","# Create an SVM classifier with a linear kernel\n","classifier = SVC(kernel='linear', random_state=0)\n","\n","# Fit the classifier on the training data\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = classifier.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy:.2f}')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v_eC-nghismF","executionInfo":{"status":"ok","timestamp":1696574404574,"user_tz":-330,"elapsed":2291,"user":{"displayName":"Vidhya Sanjana K","userId":"10741726791244027257"}},"outputId":"8e0c0a6f-3142-467d-a8eb-42279bd47c91"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.84\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# Load the heart dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/ASW/heart.csv\")\n","\n","# Select features and target variable\n","X = df.drop('target', axis=1)\n","y = df['target']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n","\n","# Create an SVM classifier with a linear kernel\n","classifier = SVC(kernel='linear', random_state=0)\n","\n","# Fit the classifier on the training data\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = classifier.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy:.2f}')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vkap8D7v6fEr","executionInfo":{"status":"ok","timestamp":1696577797211,"user_tz":-330,"elapsed":4409,"user":{"displayName":"Vidhya Sanjana K","userId":"10741726791244027257"}},"outputId":"60921995-9c78-4612-f1ee-aef66d53ccdd"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.85\n"]}]},{"cell_type":"markdown","source":["**LOGISTIC REGRESSION**"],"metadata":{"id":"PNFO5TVyjzPK"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report  # Import accuracy_score\n","\n","# Load the heart dataset\n","df = pd.read_csv('/content/drive/MyDrive/ASW/heart.csv')\n","\n","# Select features and target variable\n","X = df.drop('target', axis=1)\n","y = df['target']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=5)\n","\n","# Standardize the feature values\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)\n","\n","# Create a Logistic Regression classifier\n","classifier = LogisticRegression()\n","\n","# Fit the classifier on the training data\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test data\n","y_pred = classifier.predict(X_test)\n","\n","print(y_pred)\n","# Evaluate the model's performance\n","accuracy = accuracy_score(y_test, y_pred)\n","report = classification_report(y_test, y_pred)\n","\n","print(f'Accuracy: {accuracy}')\n","print(report)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"weTikZX_60XT","executionInfo":{"status":"ok","timestamp":1696577840391,"user_tz":-330,"elapsed":773,"user":{"displayName":"Vidhya Sanjana K","userId":"10741726791244027257"}},"outputId":"0984bfb9-e2be-494f-d657-9f6da2ce39cc"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 1\n"," 1 1 0 1 0 0 0 1 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 1 1 0 0 0\n"," 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 1 1 0 1\n"," 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 0 0 1 0 0 0\n"," 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1\n"," 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 0 0 0 1 0 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 0 0\n"," 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 0]\n","Accuracy: 0.8521400778210116\n","              precision    recall  f1-score   support\n","\n","           0       0.93      0.77      0.84       131\n","           1       0.80      0.94      0.86       126\n","\n","    accuracy                           0.85       257\n","   macro avg       0.86      0.85      0.85       257\n","weighted avg       0.86      0.85      0.85       257\n","\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report  # Import accuracy_score\n","\n","# Load the heart dataset\n","df = pd.read_csv('/content/drive/MyDrive/ASW/heart.csv')\n","\n","# Select features and target variable\n","X = df.drop('target', axis=1)\n","y = df['target']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n","\n","# Standardize the feature values\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)\n","\n","# Create a Logistic Regression classifier\n","classifier = LogisticRegression()\n","\n","# Fit the classifier on the training data\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test data\n","y_pred = classifier.predict(X_test)\n","\n","print(y_pred)\n","# Evaluate the model's performance\n","accuracy = accuracy_score(y_test, y_pred)\n","report = classification_report(y_test, y_pred)\n","\n","print(f'Accuracy: {accuracy}')\n","print(report)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zvAM8Vktj8yg","executionInfo":{"status":"ok","timestamp":1696522208844,"user_tz":-330,"elapsed":425,"user":{"displayName":"Vidhya Sanjana K","userId":"10741726791244027257"}},"outputId":"9f1f0936-88d2-4b8c-8236-d150d7425867"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 1 0 1 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1\n"," 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0\n"," 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1\n"," 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 1 1 0\n"," 1 0 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1\n"," 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 1\n"," 1 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1 0 1]\n","Accuracy: 0.8638132295719845\n","              precision    recall  f1-score   support\n","\n","           0       0.91      0.80      0.85       123\n","           1       0.83      0.93      0.88       134\n","\n","    accuracy                           0.86       257\n","   macro avg       0.87      0.86      0.86       257\n","weighted avg       0.87      0.86      0.86       257\n","\n"]}]},{"cell_type":"markdown","source":["**KNN**\n"],"metadata":{"id":"iD69Jlelns92"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# Load the heart dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/ASW/heart.csv\")\n","\n","# Select features (X) and target variable (y)\n","X = df.drop('target', axis=1)\n","y = df['target']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","# Create a KNN classifier\n","classifier = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n","\n","# Fit the classifier on the training data\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = classifier.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy:.2f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ecXSWj0-5klz","executionInfo":{"status":"ok","timestamp":1696577998646,"user_tz":-330,"elapsed":7,"user":{"displayName":"Vidhya Sanjana K","userId":"10741726791244027257"}},"outputId":"2125df8b-359b-4195-ccac-8c9d53fa0e04"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.75\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# Load the heart dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/ASW/heart.csv\")\n","\n","# Select features (X) and target variable (y)\n","X = df.drop('target', axis=1)\n","y = df['target']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","# Create a KNN classifier\n","classifier = KNeighborsClassifier(n_neighbors=10, metric='minkowski', p=2)\n","\n","# Fit the classifier on the training data\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = classifier.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy:.2f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zK0A1HxwmrjT","executionInfo":{"status":"ok","timestamp":1696577986063,"user_tz":-330,"elapsed":740,"user":{"displayName":"Vidhya Sanjana K","userId":"10741726791244027257"}},"outputId":"b83ab3e3-4184-4277-853d-dde92fe09bbb"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.80\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# Load the heart dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/ASW/heart.csv\")\n","\n","# Select features (X) and target variable (y)\n","X = df.drop('target', axis=1)\n","y = df['target']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","# Create a KNN classifier\n","classifier = KNeighborsClassifier(n_neighbors=2, metric='minkowski', p=2)\n","\n","# Fit the classifier on the training data\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = classifier.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy:.2f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zsK7R7Vj5p1L","executionInfo":{"status":"ok","timestamp":1696577606334,"user_tz":-330,"elapsed":427,"user":{"displayName":"Vidhya Sanjana K","userId":"10741726791244027257"}},"outputId":"3bc52e1a-35e3-4f62-b68b-74b94eed3377"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.95\n"]}]},{"cell_type":"markdown","source":["**NAIVE BAYES**\n"],"metadata":{"id":"5VjvQiPdo1vw"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import accuracy_score\n","\n","# Load the heart dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/ASW/heart.csv\")\n","\n","# Select features (X) and target variable (y)\n","x = df.drop('target', axis=1)\n","y = df['target']\n","\n","# Split the data into training and testing sets\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n","\n","# Create a Gaussian Naive Bayes classifier\n","model = GaussianNB()\n","\n","# Fit the classifier on the training data\n","model.fit(x_train, y_train)\n","\n","# Make predictions on the test data\n","y_pred = model.predict(x_test)\n","\n","print(y_pred)\n","\n","# Calculate the accuracy of the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oD5-tRM2ohG5","executionInfo":{"status":"ok","timestamp":1696577630229,"user_tz":-330,"elapsed":410,"user":{"displayName":"Vidhya Sanjana K","userId":"10741726791244027257"}},"outputId":"3c11fe83-80fe-45ba-a66d-729b74b4c83e"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 0 1 0 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 1 0 1\n"," 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 1 1\n"," 0 1 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1\n"," 1 1 0 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0\n"," 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0\n"," 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 0 0 1 1 0 0\n"," 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 0 0 0 1 0 1 1 0 0]\n","Accuracy: 0.8443579766536965\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import accuracy_score\n","\n","# Load the heart dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/ASW/heart.csv\")\n","\n","# Select features (X) and target variable (y)\n","x = df.drop('target', axis=1)\n","y = df['target']\n","\n","# Split the data into training and testing sets\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=32)\n","\n","# Create a Gaussian Naive Bayes classifier\n","model = GaussianNB()\n","\n","# Fit the classifier on the training data\n","model.fit(x_train, y_train)\n","\n","# Make predictions on the test data\n","y_pred = model.predict(x_test)\n","\n","print(y_pred)\n","\n","# Calculate the accuracy of the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RDHmnL_D6GIe","executionInfo":{"status":"ok","timestamp":1696577691211,"user_tz":-330,"elapsed":397,"user":{"displayName":"Vidhya Sanjana K","userId":"10741726791244027257"}},"outputId":"8b23e6c7-fab9-4a69-ef97-0f977a90c33e"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 0 1 0 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 1 0 1\n"," 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 1 1\n"," 0 1 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1\n"," 1 1 0 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0\n"," 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0\n"," 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 0 0 1 1 0 0\n"," 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 0 0 0 1 0 1 1 0 0]\n","Accuracy: 0.8443579766536965\n"]}]}]}